# ğŸ§  Improved ETL Agent

This project contains a privacy-aware, Dockerized ETL (Extract, Transform, Load) pipeline designed for preprocessing industrial datasets like SECOM. It supports outlier removal, imputation, normalization, and optional PII detection using Gemini + Presidio.

---

## ğŸ“† Features

* ğŸ“Š Cleans and imputes missing sensor data
* ğŸ” Optional PII detection using Microsoft Presidio
* ğŸ” Gemini API integration for text redaction
* ğŸ³ Dockerized for consistency and easy deployment
* âœ… Works with SECOM and other tabular time-series datasets

---

## âš›ï¸ Step-by-Step Setup

### â™»ï¸ 1. Clone the Repository

```bash
git clone https://github.com/iampruh887/cli-etl-agent.git
cd cli-autoetl-agent
```

---

### ğŸ“ 2. Add Your Data Files

Place your CSV files in the following directory:

```bash
cli_autoetl_agent/deploy/data/
```

Example:

```bash
cp /path/to/secom_data.csv ./deploy/data/
cp /path/to/secom_labels.csv ./deploy/data/
```

---

### ğŸ”‘ 3. Add Your Gemini API Key

1. Copy the sample `.env` file:

```bash
cp deploy/.env.example deploy/.env
```

2. Edit the `.env` file and add your Gemini API key:

```env
GEMINI_API_KEY=your_api_key_here
```

---

### ğŸ³ 4. Install Docker & Docker Compose

If you donâ€™t have them installed:

* [Install Docker](https://docs.docker.com/get-docker/)
* [Install Docker Compose](https://docs.docker.com/compose/install/)

---

### âš¡ 5. Run the Setup Script

```bash
cd deploy
./deploy.sh
```

This script will:

* Create required folders (`data/`, `output/`, `logs/`)
* Ensure `.env` is in place
* Pull the latest Docker image

---

### â–¶ï¸ 6. Launch the ETL Agent

Run in interactive mode:

```bash
docker-compose up etl-agent-interactive
```

Once inside the container:

```bash
python improved_etl.py --source /app/data/secom_labels.csv /app/data/secom_data.csv
```

Cleaned output will be saved to:

```
deploy/output/
```

---

## ğŸ“ Folder Structure

```bash
cli_autoetl_agent/
â”œâ”€â”€ improved_etl.py          # Main ETL logic
â”œâ”€â”€ Dockerfile               # Container build file
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ deploy/
â”‚   â”œâ”€â”€ deploy.sh            # Bootstrap script
â”‚   â”œâ”€â”€ docker-compose.yml   # Compose setup
â”‚   â”œâ”€â”€ .env.example         # Gemini key template
â”‚   â”œâ”€â”€ data/                # Place CSV input files here
â”‚   â”œâ”€â”€ output/              # Output will be saved here
â”‚   â””â”€â”€ logs/                # Optional logging
```

---

## ğŸ§° Optional: Run with Docker Only

You can skip Docker Compose and run the agent directly:

```bash
docker run -it --rm \
  -e GEMINI_API_KEY="your_api_key_here" \
  -v $(pwd)/deploy/data:/app/data:ro \
  -v $(pwd)/deploy/output:/app/output \
  yourdockerhubusername/etl-agent:latest \
  --source /app/data/secom_labels.csv /app/data/secom_data.csv
```

---

## ğŸ“‹ Requirements

* Docker
* Docker Compose
* Gemini API Key: [https://aistudio.google.com/apikey](https://aistudio.google.com/apikey)


---

## ğŸ¤‘ License

This project is licensed under the MIT License.

---

## ğŸ§  Credits

Built with â¤ï¸ by [iampruh887](https://github.com/iampruh887)
